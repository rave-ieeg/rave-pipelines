---
title: "RAVE Power Explorer"
format: html
output:
  html_document: default
  pdf_document: default
editor_options:
  chunk_output_type: console
chunk_output_type: console
---

```{r setup, include = FALSE}
# This code block sets up the engine environment
# Please do not remove me
ravepipeline::pipeline_setup_rmd("power_explorer")

options(knit_rave_pipelines = TRUE)
```

```{rave check_load_power, language = "R", export = "repository", format = "rave_prepare_power"}
subject <- raveio::as_rave_subject(subject_id = sprintf("%s/%s", project_name, subject_code))

if(exists('epoch_choice__load_single_trial') && isTRUE(epoch_choice__load_single_trial)) {
  
  to_ep <- function(en) {
    file.path(subject$meta_path, paste0('epoch_', en, '.csv'))
  }
  
  # write out a single trial epoch file
  ec2 <- paste0('single_trial_', epoch_choice)
  ec2_path <- to_ep(ec2)
  
  ep <- read.csv(to_ep(epoch_choice))
  block1 <- subset(ep, ep$Block == ep$Block[1])
  mx_time <- max(block1$Time) - min(block1$Time) + epoch_choice__trial_ends
  
  # write out a dummy epoch file that passes the necessary checks  
  write.csv(x = block1[1, , drop=FALSE], 
            file=ec2_path, row.names = FALSE)
  
  repository <- raveio::prepare_subject_power(
    subject = subject, electrodes = loaded_electrodes, 
    epoch_name = ec2, reference_name = reference_name,
    
    time_windows = c(epoch_choice__trial_starts, mx_time)
  )
  
} else {
  repository <- raveio::prepare_subject_power(
    subject = subject, electrodes = loaded_electrodes, 
    epoch_name = epoch_choice, reference_name = reference_name,
    time_windows = c(epoch_choice__trial_starts, epoch_choice__trial_ends))
}

repository
```

```{rave check_requested_electrodes, language = "R", export = "requested_electrodes"}
requested_electrodes <- dipsaus::parse_svec(analysis_electrodes, sep=',|;', connect  = ':-')
requested_electrodes <- requested_electrodes[requested_electrodes %in% repository$power$dimnames$Electrode]
if(!length(requested_electrodes)){ stop("No electrode selected") }
```

```{rave check_analysis_settings, language = "R", export = "analysis_settings_clean"}
check_range <- function(x, lim, lbl) {
  if(!all(x %within% lim)) stop(sprintf('Requested %s [%s] not within available range [%s]', lbl, str_collapse(range(x), ':'), str_collapse(range(lim), ':')), call. = FALSE)
}

# check repo settings
if(length(repository$time_windows) != 1) stop('discontinuous time windows not supported')

# first ensure all analysis settings are vectors, not lists
analysis_settings_clean <- lapply(analysis_settings, function(as) {
  as$time %<>% unlist
  as$frequency %<>% unlist
  
  if(is.null(as$label) || nchar(as$label) < 1) {
    as$label <- paste('Window', rand_string(length = 4))
  }
  
  if(is.null(as$censor_info)) {
    as$censor_info <- list(
      enabled=FALSE, window = 0:1
    )
  }
  
  return(as)
})

# ensure baseline choices are valid
ua <- get_unit_of_analysis(names=TRUE)
if(!baseline_settings$unit_of_analysis %in% ua) {
  stop(sprintf('Requested unit of analysis "%s" must be one of: %s', baseline_settings$unit_of_analysis, str_collapse(ua)))
}

ua <- get_baseline_scope(names=TRUE)
if(!baseline_settings$scope %in% ua) {
  stop(sprintf('Requested baseline scope "%s" must be one of: %s', baseline_settings$scope, str_collapse(ua)))
}

# ensure analysis choices are valid
epoch_event_types = get_available_events(repository$epoch$columns)
lapply(analysis_settings_clean, function(setting) {
  # setting <- analysis_settings_clean$TO
  
  check_range(setting$frequency, unlist(repository$frequency), 'frequency')
  check_range(setting$time, unlist(repository$time_windows), 'analysis time')
  
  if(!(setting$event %in% epoch_event_types)){
    stop(sprintf('Requested event "%s" must be one of: %s', setting$event, str_collapse(epoch_event_types)))
  }
})

names(analysis_settings_clean) <- sapply(analysis_settings_clean, `[[`, 'label')

#ensure no duplicated names
dd <- duplicated(sapply(analysis_settings_clean, `[[`, 'label'))
while(sum(dd)) {
  for(w in which(dd)) {
    analysis_settings_clean[[w]]$label = paste(analysis_settings_clean[[w]]$label,
                                               rand_string(length = 4))
  }
  dd <- duplicated(sapply(analysis_settings_clean, `[[`, 'label'))
}

# copy in the censor variable into the analysis settings. if the censoring changes,
# basically everything changes
for(ii in seq_along(analysis_settings_clean)) {
  analysis_settings_clean[[ii]]$censor_info = time_censor
  analysis_settings_clean[[ii]]$censor_info$window %<>% unlist
}


#### checks on condition groupings
for(ii in seq_along(first_condition_groupings)) {
  if(!nzchar(first_condition_groupings[[ii]]$label)) {
    first_condition_groupings[[ii]]$label = paste('Group', ii)
  }
}

#ensure no duplicate condition names
dd <- duplicated(sapply(first_condition_groupings, `[[`, 'label'))
while(sum(dd)) {
  for(w in which(dd)) {
    first_condition_groupings[[w]]$label = paste(first_condition_groupings[[w]]$label,
                                                 rand_string(length = 4))
  }
  dd <- duplicated(sapply(first_condition_groupings, `[[`, 'label'))
}

# ensure second-level trial groupings accord with the first level
fcg <- c(unlist(sapply(first_condition_groupings, `[[`, 'conditions')))
if(isTRUE(enable_second_condition_groupings)) {
  scg <- c(unlist(sapply(second_condition_groupings, `[[`, 'conditions')))
  stopifnot(setequal(scg,fcg))
  stopifnot(all(!duplicated(scg)))
}

# we can't have duplicates in trial groupings
if(any(duplicated(fcg))) {
  warning("Duplication in first factor, results may be unreliable")
}

if(is.list(trial_outliers_list)) {
  trial_outliers_list %<>% unlist
}


## add in the subejct code to the analysis settings
for(ii in seq_along(analysis_settings_clean)) {
  analysis_settings_clean[[ii]]$subject_code = subject_code
  analysis_settings_clean[[ii]]$project_name = project_name
}


# if we have a custom ROI analysis, the we need to create new analysis settings objects from these --
# We're doing this here rather than in the GUI because the UI would be cumbersome. The drop-down for 
# how to treat the custom roi (filter, stratify, interaction) is doing the signifying work
if(all(isTRUE(enable_custom_ROI), custom_roi_variable != 'none', custom_roi_type != 'Filter only')) {
  
  nms <- names(analysis_settings_clean)
  roi_nms <- sapply(custom_roi_groupings, `[[`, 'label')
  
  names(custom_roi_groupings) <- roi_nms
  
  
  nm.grid <- expand.grid('asc'=nms, 'roi'=roi_nms)
  
  new_asc <- vector('list')
  
  for(ii in 1:nrow(nm.grid)) {
    tmp <- analysis_settings_clean[[nm.grid$asc[ii]]]
    
    tmp$electrodes = dipsaus::parse_svec(custom_roi_groupings[[nm.grid$roi[ii]]]$electrodes)
    tmp$roi_label = custom_roi_groupings[[nm.grid$roi[ii]]]$label
    tmp$roi_conditions = custom_roi_groupings[[nm.grid$roi[ii]]]$conditions
    
    new_asc[[paste(nm.grid$roi[ii], nm.grid$asc[ii], sep='_')]] <- tmp
  }
  
  analysis_settings_clean <- new_asc
}

analysis_checks_passed=TRUE
```

```{rave calculate_baseline, language = "R", export = "baselined_power", cue = "always", format = "user-defined-r"}

if(exists('epoch_choice__load_single_trial') && isTRUE(epoch_choice__load_single_trial)) {
  raveio::power_baseline(
    x = repository,
    baseline_windows = list(
      range(repository$time_points)
      # c(min(repository$time_points), 0)
    ),
    method = get_unit_of_analysis(baseline_settings$unit_of_analysis),
    units = get_baseline_scope(baseline_settings$scope),
    signal_type = "LFP",
    electrodes = requested_electrodes
  )
  
  
  # els <- which(repository$electrode_list %in% requested_electrodes)
  # bpdim <- dim(repository$power$data_list[[els[1]]])
  # bpdim[4] <- length(els)
  # baselined_power <- array(0, dim = bpdim)
  # for(ei in seq_along(els)) {
  #   
  #   baselined_power[,,,ei] <- repository$power$data_listrepository$electrode_list[els]
  # }
  # 
  # lapply(repository$power$data_list[els], function(ee) {
  #   els
  # })
  
  
} else {
  raveio::power_baseline(
    x = repository,
    baseline_windows = baseline_settings$window,
    method = get_unit_of_analysis(baseline_settings$unit_of_analysis),
    units = get_baseline_scope(baseline_settings$scope),
    signal_type = "LFP",
    electrodes = requested_electrodes
  )
}
baselined_power <- repository$power$baselined

```

```{rave build_trial_details, language = "R", export = "trial_details"}
# remove empty FCGs
k = sapply(lapply(first_condition_groupings, `[[`, 'conditions'), length)
fcgs <- first_condition_groupings[k>0]

all_trials <- c(unname(unlist(lapply(fcgs, `[[`, 'conditions'))))
ep_table <- repository$epoch$table

tbl <- subset(ep_table, ep_table[[condition_variable]] %in% all_trials,
              select=c('Trial', condition_variable))

f1 <- rutabaga::rbind_list(
  lapply(fcgs, function(ff) {
    # ff = fcgs[[1]]
    df = list()
    df[[condition_variable]] =ff$conditions
    df$Factor1 =ff$label
    
    as.data.frame(df)
  })
)

trial_details <- merge(tbl, f1, by=condition_variable)

if(isTRUE(enable_second_condition_groupings)) {
  f2 <- rutabaga::rbind_list(
    lapply(second_condition_groupings, function(ff) {
      # ff = second_condition_groupings[[1]]
      # data.frame('Factor2'=ff$label, 'Condition'=ff$conditions)
      
      df = list()
      df[[condition_variable]] =ff$conditions
      df$Factor2 =ff$label
      
      as.data.frame(df)
    })
  )
  
  trial_details %<>% merge(f2, by=condition_variable)
}

# order the trial details by trial number
trial_details = trial_details[order(trial_details$Trial),]

# put the factors in order
trial_details$Factor1 %<>% factor(levels = sapply(fcgs, `[[`, 'label'))

if(!is.null(trial_details$Factor2)) {
  trial_details$Factor2 %<>% factor(levels = sapply(second_condition_groupings, `[[`, 'label'))
}

# add rownames to trial details to make for easy selection by trial
rownames(trial_details) = trial_details$Trial
```

```{rave build_analysis_groups, language = "R", export = "analysis_groups"}
# build the groups from the first_condition_groupings variable (eventually add in the 2 cond group)
if(isTRUE(enable_second_condition_groupings)) {
  # remove empty FCGs
  
  by_group <- split(trial_details,
                    list(trial_details$Factor1, trial_details$Factor2)
  )
  
  # names(by_group)
  # the names should be set automatically, and this way we don't have to worry
  # about getting the order correct
  # names(by_group) <- paste(rep(levels(trial_details$Factor1),
  # each=nlevels(trial_details$Factor2)), levels(trial_details$Factor2), sep='.')
  
  analysis_groups <- vector('list', length(by_group))
  for(ii in seq_along(by_group)) {
    analysis_groups[[ii]] <- list(
      label = names(by_group)[[ii]],
      conditions = unique(by_group[[ii]]$Condition),
      condition_per_trial = by_group[[ii]]$Condition,
      trials = by_group[[ii]]$Trial,
      index = ii,
      has_trials = TRUE#,
      # this shouldn't be requested electrodes,
      # this should be set based on some grouping variable like ROI
      #electrodes = requested_electrodes
    )
  }
  
  attr(analysis_groups, 'meta') <- trial_details
  
} else {
  analysis_groups <- mapply(function(cg, ii) {
    trials <- c()
    if(length(cg$conditions)>0) {
      trials <- repository$epoch$table$Trial[
        repository$epoch$table[[condition_variable]] %in% cg$conditions
      ]
    }
    
    list(
      label = cg$label,
      conditions = cg$conditions,
      trials = trials,
      index = ii,
      has_trials = length(trials) > 0#,
      # electrodes = requested_electrodes
    )
  }, first_condition_groupings, seq_along(first_condition_groupings), SIMPLIFY = FALSE)
  
  # remove groups that have no data
  has_trials <- which(sapply(analysis_groups, `[[`, 'has_trials'))
  analysis_groups = analysis_groups[has_trials]
}

if(!exists('epoch_choice__load_single_trial') || !isTRUE(epoch_choice__load_single_trial)) {
  if(length(analysis_groups) < 1) {
    stop('No trials available in condition groups')
  }
}

# bring up the label as the element name for ease of use
names(analysis_groups) <- sapply(analysis_groups, `[[`, 'label')
```

```{rave build_pluriform_power, language = "R", export = "pluriform_power", format = "user-defined-r"}
pluriform_power <- NULL
# Depends on baselined_power, 
# epoch_event_types = get_available_events(repository$epoch$columns)
# 
# baselined_power_data <- subset(baselined_power,
#                                Electrode ~ Electrode %in% requested_electrodes)
# 
# microbenchmark('a'={
# 
# pluriform_power <- lapply(
#   analysis_groups,
#   # callback = function(x) {
#   #   paste('[build_pluriform_power] working on:', x$label, 'data')
#   # }, 
#   FUN = function(ag) {
#     # ag = analysis_groups[[2]]
#     # for each analysis group, run through each analysis setting
#     sapply(analysis_settings_clean, function(as) {
#       # as <- analysis_settings_clean[[1]]
#       p <- get_pluriform_power(
#         baselined_data=baselined_power_data,
#         trial_indices = ag$trials,
#         events = repository$epoch$table,
#         epoch_event_types = epoch_event_types,
#         trial_outliers_list=unlist(trial_outliers_list),
#         event_of_interest = as$event,
#         sample_rate = repository$subject$power_sample_rate
#       )
#       list('data'=p, 'settings'=as, 'outliers' = trial_outliers_list)
#     }, simplify = FALSE, USE.NAMES = TRUE)
#   })
# 
# }, 'b' = {
#   

## time shifting is very slow, so do it all at once. Time shift all necessary trials first (much like how we baseline everything)
# then split into trial groups

# this is slower when you only have one analysis setting, but not by much? I guess we could detect how many analysis settings you have
# and then use the different function? if it's 65 ms, maybe doesn't matter 

# str(pluriform_power[[1]]$TO$data$events)
# str(asc$TO$data$data)
# 
# data_by_asc <- sapply(analysis_settings_clean, function(as) {
#   # as <- analysis_settings_clean[[1]]
#   p <- get_pluriform_power(
#     baselined_data=baselined_power_data,
#     trial_indices = trial_details$Trial,
#     events = repository$epoch$table,
#     epoch_event_types = epoch_event_types,
#     trial_outliers_list=unlist(trial_outliers_list),
#     event_of_interest = as$event,
#     sample_rate = repository$subject$power_sample_rate
#   )
#   return(list('data'=p, 'settings'=as, 'outliers' = trial_outliers_list))
# }, simplify = FALSE, USE.NAMES = TRUE)
# 
# data_vars <- c('data', 'shifted_data', 'clean_data', 'shifted_clean_data')
# pluriform_power <- sapply(analysis_groups, function(ag) {
#   # ag <- analysis_groups[[1]]
#   re <- sapply(data_by_asc, function(dba) {
#     # dba <- data_by_asc[[1]]
#     
#     # dba$data$events %<>% subset((.)$Trial %in% ag$trials)
#     
#     ti <- as.numeric(dimnames(dba$data$data)$Trial) %in% ag$trials
#     # for(dv in data_vars) {
#     #   # dv = 'data'
#     #   dba$data[[dv]] <- dba$data[[dv]][,,ti,,drop=FALSE]
#     # }
#     
#     dba$data[data_vars] <- lapply(dba$data[data_vars], function(dd) {
#       dd[,,ti,,drop=FALSE]
#     })
#     
#     # make sure everything lines up (this is fatal, so don't allow continuation on error)
#     # stopifnot(
#     #   all(nrow(dba$data$events) == unique(unlist(sapply(data_vars, function(dv) dim(dba$data[[dv]])[3]))))
#     # )
#     
#     dba    
#   }, simplify=FALSE, USE.NAMES=TRUE)
# }, simplify = FALSE, USE.NAMES = TRUE)
# 
# # }, times=50, check='equal')
# 
# # now create frequency-subsetted versions of the data
# for(gg in seq_along(pluriform_power)) {
#   for(aa in seq_along(pluriform_power[[gg]])) {
#     fi <- as.numeric(dimnames(pluriform_power[[gg]][[aa]]$data$shifted_data)$Frequency) %within% 
#       unlist(pluriform_power[[gg]][[aa]]$settings$frequency)
#     
#     pluriform_power[[gg]][[aa]]$data$shifted_data_Fsub <- pluriform_power[[gg]][[aa]]$data$shifted_data[fi,,,,drop=FALSE]
#     
#     pluriform_power[[gg]][[aa]]$data$shifted_clean_data_Fsub <-  pluriform_power[[gg]][[aa]]$data$shifted_clean_data[fi,,,,drop=FALSE]
#   }
# }



```

```{rave build_by_frequency_over_time_data, language="R", export="by_frequency_over_time_data"}
# the idea is that we don't need the full tensor for any given analysis,
# and so it's better (space if not time, and less space means easier multithreading so faster) to have smaller data files to cache

# grab only the electrodes we need
baselined_power_data <- subset(baselined_power,
                               Electrode ~ Electrode %in% requested_electrodes)
epoch_event_types = get_available_events(repository$epoch$columns)

# flatten the settings / trial group hierarchy with the do.call(c, ...)
by_frequency_over_time_data <- do.call(
  c,
  
  sapply(analysis_settings_clean, function(asc) {
    # asc <- analysis_settings_clean[[1]]
    
    # 1) collapse over electrode
    # 2) shift the data in time (different shift per trial, so don't collapse over trial yet), 
    # 3) then collapse over trial
    
    # check if this analysis settings is specifying an electrode subset
    dn_el <- as.integer(dimnames(baselined_power_data)$Electrode)
    electrodes_to_use <- dn_el
    
    if(!is.null(asc[['electrodes']])) {
      electrodes_to_use <- electrodes_to_use[electrodes_to_use %in% asc$electrodes]
    }
    
    ei <- which(dn_el %in% electrodes_to_use)
    
    collapse_e <- raveio::collapse2(baselined_power_data[,,,ei,drop=FALSE], keep = 1:3, method = "mean")
    
    # add back in the 4th dimension (electrode) b/c the shift function expects it
    dim(collapse_e) = c(dim(baselined_power_data)[1:3], 1)
    dimnames(collapse_e) <- append(dimnames(baselined_power_data)[1:3], list('Electrode'='Avg'))
    
    # 2
    re <- shift_baselined_power(
      baselined_data=collapse_e,
      events = repository$epoch$table,
      epoch_event_types = epoch_event_types,
      event_of_interest = asc$event,
      sample_rate = repository$subject$power_sample_rate
    )
    
    # now that we've shifted the data, split into analysis groups and then collapse over trial 
    all_ag <- sapply(analysis_groups, function(ag) {
      # get the trials we need
      
      trials_to_keep <- ag$trials
      if(!is.null(trial_outliers_list)) {
        trials_to_keep <- trials_to_keep[! trials_to_keep %in% trial_outliers_list]
      }
      
      ti <- as.numeric(dimnames(re$data)$Trial) %in% trials_to_keep
      
      # 3 now collapse over trial (and drop the electrode dimension)
      ag$data = raveio::collapse2(re$data[,,ti,,drop=FALSE], keep = 2:1, method = "mean")
      
      # dimnames(ag$data) <-
      ag$x = as.numeric(dimnames(re$data)$Time)
      ag$y = as.numeric(dimnames(re$data)$Frequency)
      ag$xlab = 'Time (s)'
      ag$ylab = 'Frequency'
      ag$zlab = "Mean " %&% baseline_settings$unit_of_analysis
      
      ag$condition_group = ag$label
      ag$electrodes <- electrodes_to_use
      
      # ag$settings = asc
      ag$outliers = trial_outliers_list
      ag$events = subset(re$events, Trial %in% ag$trials)
      
      ag %<>% add_analysis_settings(asc, baseline_settings)
      
      ag$range = range(ag$data)
      
      ag
    }, simplify=FALSE)
    
    return(all_ag)
    
  }, simplify = FALSE, USE.NAMES = TRUE)
)

```

```{rave build_by_frequency_correlation_data, language="R", export = "by_frequency_correlation_data"}
# for each analysis settings in the by_frequency_over_time_data, get the correlation within the time window

# get the average response for _each_ frequency on _each_ trial,
# averaged across electrodes and time points within the analysis window


# grab only the electrodes we need
baselined_power_data <- subset(baselined_power,
                               Electrode ~ Electrode %in% requested_electrodes)

epoch_event_types = get_available_events(repository$epoch$columns)

# flatten the settings / trial group hierarchy with the do.call(c, ...)
by_frequency_correlation_data <- do.call(
  c,
  
  sapply(analysis_settings_clean, function(asc) {
    # asc <- analysis_settings_clean$TO
    
    # 1) collapse over electrode
    # 2) shift the data in time
    # 3) collapse in analysis window
    
    # check if this analysis settings is specifying an electrode subset
    dn_el <- as.integer(dimnames(baselined_power_data)$Electrode)
    electrodes_to_use <- dn_el
    
    if(!is.null(asc[['electrodes']])) {
      electrodes_to_use <- electrodes_to_use[electrodes_to_use %in% asc$electrodes]
    }
    
    ei <- which(dn_el %in% electrodes_to_use)
    
    collapse_e <- raveio::collapse2(baselined_power_data[,,,ei,drop=FALSE], keep = 1:3, method = "mean")
    
    # add back in the 4th dimension (electrode) b/c the shift function expects it
    dim(collapse_e) = c(dim(baselined_power_data)[1:3], 1)
    dimnames(collapse_e) <- append(dimnames(baselined_power_data)[1:3], list('Electrode'='Avg'))
    
    # 2
    re <- shift_baselined_power(
      baselined_data=collapse_e,
      events = repository$epoch$table,
      epoch_event_types = epoch_event_types,
      event_of_interest = asc$event,
      sample_rate = repository$subject$power_sample_rate
    )
    
    # now that we've shifted the data, split into analysis groups average analysis window and correlate across trials
    all_ag <- sapply(analysis_groups, function(ag) {
      # get the trials we need
      
      trials_to_keep <- ag$trials
      if(!is.null(trial_outliers_list)) {
        trials_to_keep <- trials_to_keep[! trials_to_keep %in% trial_outliers_list]
      }
      
      ti <- as.numeric(dimnames(re$data)$Trial) %in% trials_to_keep
      aw <- as.numeric(dimnames(re$data)$Time) %within% asc$time
      
      # 3 now collapse over trial (and drop the electrode dimension)
      tmp = raveio::collapse2(re$data[,aw,ti,,drop=FALSE], keep = c(3,1), method = "mean")
      ag$data = cor(tmp)
      
      ag$y = as.numeric(dimnames(re$data)$Frequency)
      ag$x = ag$y
      ag$xlab = 'Frequency'
      ag$ylab = 'Frequency'
      ag$zlab = "Pearson correlation, Trial-level response"
      
      
      ag$range =c(-1,1)
      
      
      ag$condition_group = ag$label
      ag$electrodes <- electrodes_to_use
      
      # ag$settings = asc
      ag$outliers = trial_outliers_list
      ag$events = subset(re$events, Trial %in% ag$trials)
      
      ag %<>% add_analysis_settings(asc, baseline_settings)
      
      ag
    }, simplify=FALSE)
    
    return(all_ag)
    
  }, simplify = FALSE, USE.NAMES = TRUE)
)

```

```{rave build_by_trial_tf_data, language="R", export ="by_trial_tf_data"}
by_trial_tf_data = NULL

# build_data <- function(dd, settings) {
#   to_keep <- sapply(c('Time', 'Trial'), which.equal, names(dimnames(dd)))
#   res <- list(
#     data = ravetools::collapse(dd, keep = to_keep),
#     xlab='Time (s)', ylab='Original Trial #',
#     zlab='Mean ' %&% baseline_settings$unit_of_analysis
#   )
#   
#   res[c('x', 'y')] <- dimnames(dd)[to_keep] %>% lapply(as.numeric)
#   
#   res$N = dim(dd)[4L]
#   
#   if(isTRUE(settings$censor_info$enabled)) {
#     ti = res$x %within% settings$censor_info$window
#     res$range <- range(res$data[!ti,])
#   } else {
#     res$range <- range(res$data)
#   }
#   
#   return(res)
# }
# 
# by_trial_tf_data <- lapply(pluriform_power, function(pp) {
#   
#   
#   # rm(pp) <- pluriform_power[[1]]
#   if(all(
#     1 == length(table(sapply(pp, function(pi) pi$settings$event))),
#     1 == length(table(sapply(pp, function(pi) str_collapse(pi$settings$frequency))))
#   )) {
#     # all analysis groups have the same time=0 and the same frequency range,
#     # so we can show them on the same plot      
#     build_data(pp[[1]]$data$shifted_data_Fsub, pp[[1]]$settings)
#   } else {
#     # analysis groups have different time shifts/frequencies, so they can not be shown on the same plot
#     sapply(pp, function(ppa) {
#       build_data(ppa$data$shifted_data_Fsub, ppa$settings)
#     }, simplify = FALSE, USE.NAMES = TRUE)
#   }
# })

```

```{rave build_over_time_by_electrode_data, language="R", export ="over_time_by_electrode_data"}
# the idea is that we don't need the full tensor for any given analysis,
# and so it's better (space if not time, and less space means easier multithreading so faster) to have smaller data files to cache
# and smaller cached files are faster to load

# grab only the electrodes we need
baselined_power_data <- subset(baselined_power,
                               Electrode ~ Electrode %in% requested_electrodes)

epoch_event_types = get_available_events(repository$epoch$columns)

# flatten the settings / trial group hierarchy with the do.call(c, ...)
over_time_by_electrode_data <- do.call(
  c,
  
  sapply(analysis_settings_clean, function(asc) {
    # asc <- analysis_settings_clean[[1]]
    
    # 1) collapse over frequencies in the analysis window
    # 2) shift the data in time (different shift per trial, so don't collapse over trial yet), 
    # 3) then collapse over trial
    
    # check if this analysis settings is specifying an electrode subset
    dn_el <- as.integer(dimnames(baselined_power_data)$Electrode)
    electrodes_to_use <- dn_el
    
    if(!is.null(asc[['electrodes']])) {
      electrodes_to_use <- electrodes_to_use[electrodes_to_use %in% asc$electrodes]
    }
    
    ei <- which(dn_el %in% electrodes_to_use)
    
    fi <- as.integer(dimnames(baselined_power_data)$Frequency) %within% asc$frequency
    collapse_f <- raveio::collapse2(baselined_power_data[fi,,,ei,drop=FALSE], keep = 2:4, method = "mean")
    # 
    # # add back in the 1st dimension (freq) b/c the shift function expects it
    dim(collapse_f) = c(1, dim(baselined_power_data)[2:3], length(ei))
    dimnames(collapse_f) <- append(append(list('Frequency'='Avg'), dimnames(baselined_power_data)[2:3],),list('Electrode'=electrodes_to_use))
    
    # 2
    re <- shift_baselined_power(
      baselined_data=collapse_f,
      events = repository$epoch$table,
      epoch_event_types = epoch_event_types,
      event_of_interest = asc$event,
      sample_rate = repository$subject$power_sample_rate
    )
    
    # now that we've shifted the data, split into analysis groups and then collapse over trial 
    all_ag <- sapply(analysis_groups, function(ag) {
      # get the trials we need
      
      trials_to_keep <- ag$trials
      if(!is.null(trial_outliers_list)) {
        trials_to_keep <- trials_to_keep[! trials_to_keep %in% trial_outliers_list]
      }
      
      ti <- as.numeric(dimnames(re$data)$Trial) %in% trials_to_keep
      
      # 3 now collapse over trial (and drop the frequency dimension)
      ag$data = raveio::collapse2(re$data[,,ti,,drop=FALSE], keep = c(2,4), method = "mean")
      
      # dimnames(ag$data) <-
      ag$x = as.numeric(dimnames(re$data)$Time)
      ag$y = as.numeric(dimnames(re$data)$Electrode)
      ag$xlab = 'Time (s)'
      ag$ylab = 'Electrode'
      ag$zlab = "Mean " %&% baseline_settings$unit_of_analysis
      ag$N <- sum(ti)
      
      ag$condition_group = ag$label
      ag$electrodes <- electrodes_to_use
      
      # ag$settings = asc
      ag$outliers = trial_outliers_list
      ag$events = subset(re$events, Trial %in% ag$trials)
      
      ag %<>% add_analysis_settings(asc, baseline_settings)
      
      ag$range = range(ag$data)
      
      ag
    }, simplify=FALSE)
    
    return(all_ag)
    
  }, simplify = FALSE, USE.NAMES = TRUE)
)

```

```{rave build_over_time_by_electrode_similiarity_data, language="R", export ="by_electrode_similarity_data"}
curr_electrodes <- data.frame(NA)
all_els <- NULL
if(length(over_time_by_electrode_data) > 0) {
  all_els <- unique(unlist(lapply(over_time_by_electrode_data, `[[`, 'electrodes')))
  curr_electrodes <- subset(repository$electrode_table, Electrode %in% all_els)
}

# get the pairwise distances for electrodes, the combination rules will be done in the GUI 
# average dist, max dist, min, 
if(nrow(curr_electrodes) < 3) {
  by_electrode_similarity_data = NULL
} else {
  
  # hclust on distance matrices
  cluster_dmatrix <- function(x) {
    lapply(x, function(xx) {
      
      if(is.null(xx) || length(xx) == 0) {
        return(NULL)
      }
      
      re <- hclust(xx, method = 'ward.D2')
      re$distances <- xx
      
      return(re)
    })
  }
  
  
  # if we have custom ROIs, then we need to prefix the cluster label with the ROI label (otherwise C1 will get joined across ROIs)
  # first step is to find which groups are part of the same ROI -- we can probably guess this correctly, but feels safer to just calculate it
  roi_groups <- NULL
  if(isTRUE(enable_custom_ROI) && custom_roi_type != 'Filter only') {
    roi_groups <- sapply(over_time_by_electrode_data, `[[`, 'roi_label')
  }
  
  rownames(curr_electrodes) = curr_electrodes$Electrode
  # need to consider that we may have an ROI variable
  
  all_distances <- lapply(over_time_by_electrode_data, function(dd) {
    # dd <- over_time_by_electrode_data[[1]]
    
    etbl <- curr_electrodes[as.character(dd$electrodes),]
    
    correlation_distance <- as.dist(
      1 - cor(dd$data)
    )
    
    spearman_distance <- as.dist(
      1 - cor(dd$data, method='spearman')
    )
    
    euclidean_distance <- dist(t(dd$data), method = 'euclidean')
    coordinate_distance <- dist(etbl[,c('Coord_x', 'Coord_y', 'Coord_z')])
    
    fslabel = 'FSLabel'
    if(is.null(etbl[[fslabel]])) {
      if(!is.null(etbl['Area_fs'])) {
        etbl[[fslabel]] = etbl$Area_fs
      }
    }
    
    # assign all electrode the average coordinate of their FS label,
    # then calculate coordinate distance
    fslabel_distance = NULL
    if(!is.null(etbl[[fslabel]])) {
      tmp <- merge(etbl,
                   aggregate(cbind('CX'=Coord_x, 'CY'=Coord_y, 'CZ'=Coord_z) ~ FSLabel, FUN = mean, data=etbl)
      )
      fslabel_distance <- dist(tmp[,c('CX', 'CY', 'CZ')])
    }
    
    list(
      'correlation' = correlation_distance,
      'spearman' = spearman_distance,
      'euclidean' = euclidean_distance,
      'coordinate' = coordinate_distance,
      'FSLabel' = fslabel_distance
    )
    
  })
  
  distance_names <- names(all_distances[[1]])
  
  if(is.null(roi_groups)) {
    
  all_dist_mats <- sapply(c('total', 'max', 'min'), function(metric) {
    sapply(distance_names, function(dn) {
      FUN <- switch(metric, 
                    'total' = `+`,
                    'max' = pmax,
                    'min' = pmin
      )
      Reduce(FUN, lapply(all_distances, `[[`, dn))
    }, simplify = FALSE)
  }, simplify = FALSE)
  
  by_electrode_similarity_data <- lapply(all_dist_mats, cluster_dmatrix)
  
  } else {
    
    # handle combining distance matrices separately for each ROI
    by_roi <- sapply(unique(roi_groups), function(rg) {
      # rg <- roi_groups[[1]]
      
      roi_dists <- all_distances[roi_groups == rg]
      
      all_dist_mats <- sapply(c('total', 'max', 'min'), function(metric) {
        sapply(distance_names, function(dn) {
          FUN <- switch(metric, 
                        'total' = `+`,
                        'max' = pmax,
                        'min' = pmin
          )
          
          Reduce(FUN, lapply(roi_dists, `[[`, dn))
        }, simplify = FALSE)
      }, simplify = FALSE)
      
      
    }, simplify = FALSE)
    
    by_electrode_similarity_data <- lapply(by_roi, function(rr) {lapply(rr, cluster_dmatrix)})
  }
    
}
```

```{rave build_over_time_by_electrode_and_trial_data, language="R", export ="over_time_by_electrode_and_trial_data"}

# not implemented yet
over_time_by_electrode_and_trial_data <- NULL
build_data <- function(data, analysis_settings, condition_group, baseline_settings, ...) {
  dm <- dimnames(data)
  to_keep <- sapply(c('Time', 'Electrode', 'Trial'), which.equal, names(dm))
  res <- list(
    data = ravetools::collapse(data, keep = to_keep),
    xlab='Time (s)',
    ylab='Electrode #',
    zlab='Trial',
    analysis_unit = baseline_settings$unit_of_analysis,
    condition_group = condition_group$label,
    electrodes = as.integer(dm$Electrode)
  )
  
  res[c('x', 'y', 'z')] <- dimnames(data)[to_keep] %>% lapply(as.numeric)
  dimnames(res$data) = dimnames(data)[to_keep]
  res$N = length(dm$Trial)
  
  if(isTRUE(analysis_settings$censor_info$enabled)) {
    
    ti = res$x %within% analysis_settings$censor_info$window
    res$range <- range(res$data[!ti,,])
  } else {
    res$range <- range(res$data)
  }
  
  return(res)
}

# over_time_by_electrode_and_trial_data <- data_builder(pluriform_power = pluriform_power,
#                                                       condition_group = analysis_groups, 
#                                                       baseline_settings = baseline_settings,
#                                                       build_data)


```

```{rave build_over_time_by_condition_data, language="R", export ="over_time_by_condition_data"}

# the idea is that we don't need the full tensor for any given analysis,
# and so it's better (space if not time, and less space means easier multithreading so faster) to have smaller data files to cache

# grab only the electrodes we need
baselined_power_data <- subset(baselined_power,
                               Electrode ~ Electrode %in% requested_electrodes)
epoch_event_types = get_available_events(repository$epoch$columns)

# otbc data are not flattened... it probably should be? we rely on the structure in plotting to determine
# event vs. condition grouping, fix this
re <- #do.call(
  #c,
  sapply(analysis_settings_clean, function(asc) {
    # asc <- analysis_settings_clean[[1]]
    
    # 1) collapse over frequencies in the analysis window
    # 2) shift the data in time (different shift per trial, so don't collapse over trial yet), 
    # 3) then collapse over trial and get m_se by electrode
    fi <- as.integer(dimnames(baselined_power_data)$Frequency) %within% asc$frequency
    
    # check if this analysis settings is specifying an electrode subset
    dn_el <- as.integer(dimnames(baselined_power_data)$Electrode)
    electrodes_to_use <- dn_el
    
    if(!is.null(asc[['electrodes']])) {
      electrodes_to_use <- electrodes_to_use[electrodes_to_use %in% asc$electrodes]
    }
    
    ei <- which(dn_el %in% electrodes_to_use)
    
    
    collapse_f <- raveio::collapse2(baselined_power_data[fi,,,ei,drop=FALSE], keep = 2:4, method = "mean")
    # 
    # # add back in the 4th dimension (electrode) b/c the shift function expects it
    dim(collapse_f) = c(1, dim(baselined_power_data)[2:3], length(ei))
    dimnames(collapse_f) <- append(append(list('Frequency'='Avg'), dimnames(baselined_power_data)[2:3]), list('Electrode'=electrodes_to_use))
    
    # 2
    re <- shift_baselined_power(
      baselined_data=collapse_f,
      events = repository$epoch$table,
      epoch_event_types = epoch_event_types,
      event_of_interest = asc$event,
      sample_rate = repository$subject$power_sample_rate
    )
    
    # now that we've shifted the data, split into analysis groups and then collapse over trial 
    all_ag <- sapply(analysis_groups, function(ag) {
      # ag <- analysis_groups[[1]]
      
      # get the trials we need
      trials_to_keep <- ag$trials
      if(!is.null(trial_outliers_list)) {
        trials_to_keep <- trials_to_keep[! trials_to_keep %in% trial_outliers_list]
      }
      
      ti <- as.numeric(dimnames(re$data)$Trial) %in% trials_to_keep
      
      # 3 now collapse over trial, drop the frequency dimension, but keep electrode for now
      coll_trial = raveio::collapse2(re$data[,,ti,,drop=FALSE], keep = c(2,4), method = "mean")
      
      ag$data <- cbind(
        .rowMeans(coll_trial, nrow(coll_trial), ncol(coll_trial)),
        sqrt(diag(dipsaus::fastcov2(t(coll_trial))) / ncol(coll_trial))
      )
      
      ag$data[,2] <- ifelse(is.nan(ag$data[,2]), 0, ag$data[,2])
      
      ag$x = as.numeric(dimnames(re$data)$Time)
      ag$y = NA
      ag$xlab = 'Time (s)'
      ag$ylab = "Mean " %&% baseline_settings$unit_of_analysis
      ag$N <- dim(re$data)[4]
      
      ag$condition_group = ag$label
      ag$electrodes <- electrodes_to_use
      
      # ag$settings = asc
      ag$outliers = trial_outliers_list
      ag$events = subset(re$events, Trial %in% ag$trials)
      
      ag %<>% add_analysis_settings(asc, baseline_settings)
      
      ag$range = range(rutabaga::plus_minus(ag$data), na.rm = TRUE)
      
      ag
    }, simplify=FALSE)
    
    return(all_ag)
    
  }, simplify = FALSE, USE.NAMES = TRUE)
#)


# flip the order of conditions / events
over_time_by_condition_data <- vector('list', length = length(re[[1]]))
names(over_time_by_condition_data) = names(re[[1]])

for(ii in names(over_time_by_condition_data)) {
  for(jj in names(re)) {
    over_time_by_condition_data[[ii]][[jj]] = re[[jj]][[ii]]
  }
}

# bring down the meta data to the plotting level for ease of use
for(ii in seq_along(over_time_by_condition_data)) {
  for(jj in seq_along(over_time_by_condition_data[[ii]])) {
    over_time_by_condition_data[[ii]][[jj]]$data_label = 
      names(over_time_by_condition_data)[[ii]]
    
    over_time_by_condition_data[[ii]][[jj]]$time_window_label =
      names(over_time_by_condition_data[[ii]])[[jj]]
  }
}
```

```{rave build_over_time_by_electrode_dataframe, language='R', export = 'over_time_by_electrode_dataframe'}
over_time_by_electrode_dataframe <- NULL
# building data for the movie viewer
# first baseline all the electrodes
raveio::power_baseline(
  repository,
  baseline_windows = baseline_settings$window,
  method = get_unit_of_analysis(baseline_settings$unit_of_analysis),
  units = get_baseline_scope(baseline_settings$scope),
  signal_type = "LFP",
  electrodes = repository$electrode_list
)

# for each condition group and for each analysis setting
# get one value per TIME per electrode
# non_empty_groups <- which(rutabaga::get_list_elements(analysis_groups, 'has_trials'))

by_condition_group <- lapply(
  analysis_groups,
  # callback = function(x) {
  #   paste('[build_over_time_by_electrode_dataframe] working on:', x$label, 'data')
  # }, 
  # lapply(analysis_groups[non_empty_groups],
  FUN = function(ag) {
    
    ravedash::logger(paste(c('[build_over_time_by_electrode_dataframe] working on:', ag$label, 'data'), collapse = " "))
    
    res <- lapply(analysis_settings_clean, function(as) {
      # as = analysis_settings_clean[[1]]
      # freq needed
      fi <- repository$frequency %within% as$frequency
      
      # shift the data and subset on trials/freq
      p <- get_pluriform_power(
        baselined_data=repository$power$baselined[fi,,,,drop=FALSE],
        trial_indices = ag$trials, events = repository$epoch$table,
        epoch_event_types = get_available_events(repository$epoch$columns),
        trial_outliers_list=unlist(trial_outliers_list),
        event_of_interest = as$event, final_data_only=TRUE,
        sample_rate = repository$subject$power_sample_rate
      )
      
      # make sure dimensions are what we think they are
      stopifnot(
        names(dimnames(p)) == c('Frequency', 'Time', 'Trial', 'Electrode')
      )
      
      enames = as.integer(dimnames(p)$Electrode)
      times = as.numeric(dimnames(p)$Time)
      
      m <- ravetools::collapse(p[drop=FALSE], keep = c(4,2))
      
      df <- data.frame(
        reshape2::melt(m,
                       value.name=paste(sep='_', as$label, ag$label))
      )
      # head(df)
      names(df)[1:2] = c('Electrode', 'Time')
      df$Electrode = enames[df$Electrode]
      df$Time = times[df$Time]
      
      return(df)
    })
    
    
    if(length(res) == 1) {
      return(res[[1]])
    }
    
    # merge the data if more than one 
    merged_res <- res[[1]]
    
    for(ri in seq_along(res)[-1]) {
      merged_res = merge(merged_res, res[[ri]], all=TRUE)
    }
    
    return(merged_res)
  }
)

#merge the resulting data sets
over_time_by_electrode_dataframe <- NULL

if(length(by_condition_group) > 0) {
  over_time_by_electrode_dataframe <- by_condition_group[[1]]
  
  if(length(by_condition_group) > 1) {
    for(ii in seq_along(by_condition_group)[-1]){
      over_time_by_electrode_dataframe = merge(over_time_by_electrode_dataframe,
                                               by_condition_group[[ii]],
                                               all=TRUE)
    }
  }
}
```

```{rave build_over_time_by_trial, language="R", export ="over_time_by_trial_data"}
# grab only the electrodes we need
baselined_power_data <- subset(baselined_power,
                               Electrode ~ Electrode %in% requested_electrodes)
epoch_event_types = get_available_events(repository$epoch$columns)

over_time_by_trial_data <- do.call(
  c,
  sapply(analysis_settings_clean, function(asc) {
    # asc <- analysis_settings_clean$TO
    
    # 1) collapse over frequencies in the analysis window & electrodes
    # 2) shift the data in time
    # 3) make sure the data are sorted as needed
    
    # check if this analysis settings is specifying an electrode subset
    dn_el <- as.integer(dimnames(baselined_power_data)$Electrode)
    electrodes_to_use <- dn_el
    
    if(!is.null(asc[['electrodes']])) {
      electrodes_to_use <- electrodes_to_use[electrodes_to_use %in% asc$electrodes]
    }
    
    ei <- which(dn_el %in% electrodes_to_use)
    
    fi <- as.integer(dimnames(baselined_power_data)$Frequency) %within% asc$frequency
    collapse_fe <- raveio::collapse2(baselined_power_data[fi,,,ei,drop=FALSE], keep = 2:3, method = "mean")
    # 
    # # add back in the 4th dimension (electrode) b/c the shift function expects it
    dim(collapse_fe) = c(1, dim(baselined_power_data)[2:3], 1)
    dimnames(collapse_fe) <- append(append(list('Frequency'='Avg'), dimnames(baselined_power_data)[2:3]), list('Electrode'='Avg'))
    
    # 2
    re <- shift_baselined_power(
      baselined_data=collapse_fe,
      events = repository$epoch$table,
      epoch_event_types = epoch_event_types,
      event_of_interest = asc$event,
      sample_rate = repository$subject$power_sample_rate
    )
    
    # now that we've shifted the data, split into analysis groups and then collapse over trial 
    all_ag <- sapply(analysis_groups, function(ag) {
      # ag <- analysis_groups[[1]]
      
      # get the trials we need
      ti <- as.numeric(dimnames(re$data)$Trial) %in% ag$trials
      
      # 3 now extract the trials we need, dropping the frequency and electrode dimensions
      ag$data = re$data[,,ti,,drop=TRUE]#, keep = c(2,4), method = "mean")
      
      # if we only have 1 trial, this will collapse to a vector with length == time
      if(!is.matrix(ag$data)) {
        dim(ag$data) = c(length(ag$data), 1) 
      }
      
      ag$x = as.numeric(dimnames(re$data)$Time)
      ag$xlab = 'Time (s)'
      ag$ylab='Trial (sorted by condition)'
      ag$zlab=sprintf('Mean %s', baseline_settings$unit_of_analysis)
      
      ag$range <- range(ag$data)
      # ind <- which(sapply(first_condition_groupings, `[[`, 'label')==condition_group[[1]])
      # cnds <- first_condition_groupings[[ind]]$conditions
      
      cnds <- ag$conditions
      tt <- ag$trials
      
      ag$y <- trial_details[as.character(tt), condition_variable]
      
      cf <- factor(ag$y, levels = cnds)
      ord = order(cf, tt)
      
      # sort the trial labels
      ag$y <- ag$y[ord]
      
      # now add in trial number and outlier status, using the sorted order
      ag$trial_number = tt[ord]
      ag$is_outlier = tt[ord] %in% trial_outliers_list
      
      # NB: the condition data are stored in the COLUMNS of the data, so sort appropriately
      # this may feel odd, but this is because of how image(...) function works
      ag$data <- ag$data[ , ord, drop=FALSE]
      
      ag$N <- dim(baselined_power_data)[4]
      
      ag$condition_group = ag$label
      ag$electrodes <- electrodes_to_use
      
      # ag$settings = asc
      ag$outliers = trial_outliers_list
      ag$events = subset(re$events, Trial %in% ag$trials)
      
      ag %<>% add_analysis_settings(asc, baseline_settings)
      
      ag
    }, simplify=FALSE)
    
    return(all_ag)
    
  }, simplify = FALSE, USE.NAMES = TRUE)
)


```

```{rave build_internal_omnibus_results, language="R", export="internal_omnibus_results"}
ravedash::logger('top of IOR', level='debug')

if(isTRUE(omnibus_includes_all_electrodes)) {
  # first baseline all the electrodes
  raveio::power_baseline(
    repository,
    baseline_windows = baseline_settings$window,
    method = get_unit_of_analysis(baseline_settings$unit_of_analysis),
    units = get_baseline_scope(baseline_settings$scope),
    signal_type = "LFP",
    electrodes = repository$electrode_list
  )
  
  ob_baselined_power <- repository$power$baselined
} else {
  
  # only using requested electrodes
  ob_baselined_power <- subset(baselined_power,
                               Electrode ~ Electrode %in% requested_electrodes)
}
ravedash::logger('done baseline correction', level='debug')

epoch_event_types = get_available_events(repository$epoch$columns)

# for each condition group and for each analysis setting
# get one value per trial per electrode
# non_empty_groups <- which(rutabaga::get_list_elements(analysis_groups, 'has_trials'))

by_condition_group <- lapply(
  analysis_groups,#[non_empty_groups],
  function(ag) {
    lapply(analysis_settings_clean, function(as) {
      # as <- analysis_settings_clean[[1]]
      # freq needed
      fi <- as.integer(dimnames(ob_baselined_power)$Frequency) %within% as$frequency
      trials <- as.integer(dimnames(ob_baselined_power)$Trial) %in% ag$trials
      
      collapse_f <- raveio::collapse2(ob_baselined_power[fi,,trials,,drop=FALSE], keep = 2:4, method = "mean")
      
      # # add back in the 1st dimension (freq) b/c the shift function expects it
      dn <- dimnames(ob_baselined_power)[-1]
      dn$Trial <- dn$Trial[trials]
      dim(collapse_f) = c(1, dim(collapse_f))
      dimnames(collapse_f) <- append(list('Frequency'='Avg'), dn)
      
      # 2
      re <- shift_baselined_power(
        baselined_data=collapse_f,
        events = repository$epoch$table,
        epoch_event_types = epoch_event_types,
        event_of_interest = as$event,
        sample_rate = repository$subject$power_sample_rate
      )
      
      p <- re$data
      ti = as.numeric(dimnames(p)$Time) %within% as$time
      
      stopifnot(names(dimnames(p))[2] == 'Time')
      
      # average within Time and Freq windows. Freq has already been subsetted
      m <- ravetools::collapse(p[,ti,,,drop=FALSE], keep = 3:4)
      
      mse <- apply(m, 2, rutabaga::m_se)
      ts = mse[1,] / mse[2,]
      collapsed <- cbind(mse[1,],
                         ts,
                         2*pt(abs(ts), df = nrow(m)-1, lower.tail = F)
      )
      enames = dimnames(p)$Electrode
      rownames(collapsed) = enames
      colnames(collapsed) = paste0(c('m', 't', 'p'), '(', ag$label,   '; ', as$label, ')')
      
      trial_column <- rep(dimnames(p)$Trial, times=ncol(m))
      
      by_trial <- data.frame(
        'y' = c(m),
        'Electrode' = rep(as.numeric(enames), each=nrow(m)),
        
        # use dimnames(p) here rather than ag$Trials because of potential outliers
        'Trial' = trial_column,
        'is_clean' = !(trial_column %in% trial_outliers_list),
        'Factor1' = ag$label,
        'Time' =  't' %&% str_collapse(as$time, '-'),
        'Freq' =  'f' %&% str_collapse(as$frequency, '-'),
        'Event' = as$event,
        'AnalysisLabel' = as$label
      )
      
      return(list('df' = by_trial, 'collapsed'=collapsed))
    })
  })

all_data <- rutabaga::rbind_list(sapply(by_condition_group, 
                                        rutabaga::get_list_elements, 'df', use_sapply=FALSE))

# look for ROI labels to apply to the per-electrode data

if(all(isTRUE(enable_custom_ROI), custom_roi_variable != 'none', custom_roi_type != 'Filter only')) {

  custom_roi_groupings$C1$label
  
  # build a merge-able data frame to get the electrode ROI labels
  roi.df <- rbind_list(lapply(custom_roi_groupings, function(crg) {
    data.frame(Electrode=dipsaus::parse_svec(crg$electrodes), ROI_label = crg$label)
  }))
  
  all_data %<>% merge(roi.df, all.x=TRUE, all.y=FALSE)
}

ravedash::logger('built data frame', level='debug')
# if we have a second factor (eventually an ROI) we need to clean up the naming
if(isTRUE(enable_second_condition_groupings)) {
  meta_table <- attr(analysis_groups, 'meta')
  
  stopifnot(is.data.frame(meta_table))
  
  all_data$Factor1 = NULL
  all_data %<>% merge(meta_table, by=c('Trial'))
  
  # add in an interaction factor
  all_data$Factor1Factor2 = mapply(paste, all_data$Factor1, all_data$Factor2, sep='.')
  
  # sort the levels
  all_data$Factor1Factor2 %<>% factor(levels = names(analysis_groups))
  
} else {
  if(!is.factor(all_data$Factor1)) {
    all_data$Factor1 %<>% factor(levels = names(by_condition_group))
  }
}

# make sure analysis label is appropriately factored
if(!is.null(all_data$AnalysisLabel)) {
  all_data$AnalysisLabel %<>% factor(levels = unique(sapply(analysis_settings_clean, `[[`, 'label')))
}

if(!is.null(all_data$ROI_label)) {
  all_data$ROI_label %<>% factor(levels = unique(sapply(analysis_settings_clean, `[[`, 'roi_label')))
}

# copy of the data with the outliers removed (for stats etc)
all_data_clean <- all_data
if(!is.null(all_data[['is_clean']])) {
  all_data_clean <- subset(all_data, is_clean)
}

# collapsed_data <- cbind_list(sapply(by_condition_group, 
# get_list_elements, 'collapsed', use_sapply=FALSE))



run_stats <- function(el) {
  # for the stats, we need to figure out the factors involved and then build 
  # the appropriate model
  # for the post hocs, just get all pairwise for now. we'll need to have some
  # kind of chooser for specific contrasts in the future (duplicate with group module)
  
  get_factor_length <- function(x) length(unique(el[[x]]))
  
  repeated_factors <- 'AnalysisLabel' #c('Time', 'Freq', 'Event')
  unrepeated_factors <- c('Factor1', 'Factor2')
  factor_lengths <- sapply(c(repeated_factors, unrepeated_factors), get_factor_length)
  fixed_effects <- names(factor_lengths[factor_lengths>1])
  
  formula_str <- paste0('y ~ ', str_collapse(fixed_effects, '*'))
  if(formula_str == 'y ~ ') formula_str = 'y ~ 1' 
  
  has_re <- any(repeated_factors %in% fixed_effects)
  stat_FUN <- stats::lm
  if(has_re) {
    formula_str %<>% paste("+ (1|Trial)")
    stat_FUN <- lmerTest::lmer
  } 
  
  formula_frm = as.formula(formula_str)
  
  if(length(el$y) < 2 || var(el$y) < 1e-12) {
    return(NULL)
  }
  
  mod <- stat_FUN(formula_frm, data=el)
  
  if(length(coef(mod)) == 1 && class(mod) != 'lmerModLmerTest') {
    lsm <- emmeans::emmeans(mod, specs = '1')
    summ <- summary(lsm, infer = TRUE)
    emm = matrix(unlist(t(summ[c('emmean', 't.ratio', 'p.value')])))
    lbls <- as.character(summ[[1]])
    
    rownames(emm) = c(outer(c('m(', 't(', 'p('), lbls, paste0)) %&% ')'
    
    res <- emm
  } else {
    
    lsm <- emmeans::emmeans(mod, as.formula('pairwise ~' %&% str_collapse(fixed_effects, '*')))
    summ <- summary(lsm$emmeans, infer = TRUE)
    emm = matrix(unlist(t(summ[c('emmean', 't.ratio', 'p.value')])))
    lbls <- apply(summ[,fixed_effects,drop=FALSE], 1, str_collapse, by=' ')
    
    rownames(emm) = c(outer(c('m(', 't(', 'p('),lbls, paste0)) %&% ')'
    
    cntr = summary(lsm, adjust='fdr')$contrasts
    cmat = matrix(unlist(t(cntr[,c('estimate','t.ratio', 'p.value')])))
    rownames(cmat) = c(t(sapply(c('m(', 't(', 'p_fdr('), paste0, cntr$contrast))) %&% ')'
    
    # get the overall results to add
    tmp <- summary(emmeans::emmeans(mod, specs='1'), infer=TRUE)
    tmp.emm = matrix(unlist(t(tmp[c('emmean', 't.ratio', 'p.value')])))
    tmp.lbls <- as.character(tmp[[1]])
    
    rownames(tmp.emm) = c(outer(c('m(', 't(', 'p('), tmp.lbls, paste0)) %&% ')'
    
    res <- rbind(tmp.emm, emm, cmat)
  }
  colnames(res) = el$Electrode[1]
  
  return(res)
}

ravedash::logger('starting pes', level='debug')
# now we want to calculate the stats for each electrode
stats <- NULL
if(length(all_data_clean) > 1) {
  # make sure we have more than 1 trial per electrode
  if(min(aggregate(Trial ~ Electrode, length, data=all_data_clean)$Trial) > 1) {
    
    data_by_el <- split(all_data_clean,all_data_clean$Electrode)
    
    # raveio::lapply_async(data_by_el, FUN = run_stats, ncores=2)
    stats <- rutabaga::cbind_list(
      lapply(data_by_el, run_stats)
    )
  }
}
ravedash::logger('done pes', level='debug')

# add in electrode labels as an attribute of the stats block.
# don't add as row, otherwise we lose numeric-ness
if(!is.null(stats)) {
  attr(stats, 'electrode_labels') = repository$electrode_table$Label
}
# add in the Block information from the epoch file, could be useful to assess 
# large changes in effect size over time 
all_data %<>% merge(repository$epoch$table[,c('Block', 'Trial')], sort=FALSE)

#combine into large list for exporting
internal_omnibus_results = list(
  # 'collapsed' = collapsed_data,
  'data_with_outliers' = all_data,
  'data' = all_data_clean,
  'stats' = stats
)

ravedash::logger('done with IOR', level='debug')
```

```{rave build_omnibus_results, language="R", export="omnibus_results"}
omnibus_results = internal_omnibus_results

# to prevent needless stat recalculation when the only thing that changes is
# "requested electrodes" add in that data here in a separate block

# add in currently selected information so plots are accurate
# to selected electrodes
rn <- 'currently_selected'
while(rn %in% names(omnibus_results$data)) {
  rn <- 'PWR_EXPLR_' %&% rn
}

omnibus_results$data[[rn]] = omnibus_results$data$Electrode %in% requested_electrodes
omnibus_results$data_with_outliers[[rn]] = omnibus_results$data_with_outliers$Electrode %in% requested_electrodes


# add in "currently active" electrodes so users can filter
rn <- 'currently_selected'
while(rn %in% rownames(omnibus_results$stats)) {
  rn = 'RAVE_' %&% rn
}
val = matrix(nrow=1,
             as.integer(colnames(omnibus_results$stats) %in% as.character(requested_electrodes)),
             dimnames=list(rn))
omnibus_results$stats %<>% rbind(val)
```

```{rave build_across_electrode_statistics, language="R", export="across_electrode_statistics"}
require(data.table)
.datatable.aware = TRUE

across_electrode_statistics <- NULL
if(length(omnibus_results$data) > 3) {
  
  dd <- subset(omnibus_results$data, currently_selected)
  
  # emmeans::emm_options(lmerTest.limit = 1000)
  # emmeans::emm_options(pbkrtest.limit = 1000)
  
  # seems to be faster for large models
  emmeans::emm_options(lmer.df = "satterthwaite")
  
  # Need to think about how to handle very low trial counts for a given level of a factor
  ravedash::logger('top of BAES', calc_delta = TRUE)
  # the intersect handles variables that don't exist. We'll add Trial to RE later if possible
  rand_effects <- c('Block', 'Electrode') %>% intersect(names(dd))
  
  # we don't need "Freq" or "Event" because that is part of AnalysisLabel
  fixed_effects <- c('Factor1', 'Factor2', 'ROI_label',
                     #'Freq', 'Event', 
                     'AnalysisLabel') %>% intersect(names(dd))
  
  for(ff in c(rand_effects, fixed_effects)) {
    dd[[ff]] %<>% as.factor
  }
  
  # how many effects do we have (i.e., vars with more than one unique label)
  fe <- names(which(sapply(dd[fixed_effects], nlevels) > 1))
  re <- names(which(sapply(dd[rand_effects], nlevels) > 1))
  
  # We need to add Trial as a random effect if AnalysisLabel is a
  # fixed effect because that means a trial is used twice
  if('AnalysisLabel' %in% fe) {
    if('Block' %in% re) {
      # if we have multiple electrodes, then we can have a block/trial, 
      # otherwise we can only have 'Block'
      if('Electrode' %in% re) {
        re[which(re == 'Block')] = 'Block/Trial'
      }
    } else {
      re %<>% c('Trial')
    }
  }
  
  re_str = NULL
  if(length(re) > 0) {
    re_str <- paste(collapse='+',
                    sapply(re, function(x) sprintf("(1|%s)", x))
    )
  }
  
  
  # saveRDS('~/Desktop/v.RDS', object=list('dd'=dd, 'fe'=fe, 're_str'=re_str))
  # v <- readRDS('~/Desktop/v.RDS')
  # dd <- v$dd
  # fe <- v$fe
  # re_str <- v$re_str
  
  ## get means and trial counts. data.table is way faster than aggregate
  # ravedash::logger('Trying data.table collapse. checking DTA: ', data.table:::cedta(), calc_delta = TRUE)
  dt <- data.table::as.data.table(dd)
  condition_means <- dt[ ,list('y'=mean(y), 'sd' = sd(y),
                               'se'=rutabaga:::se(y),'n'=.N),
                         keyby=fe]
  
  ravedash::logger('got condition means', calc_delta = TRUE)
  
  # set fe to "1" (intercept only model) if there are no fixed effects. Do this 
  # after obtaining experimental means because you can't key on the number 1
  fe <- paste0(fe, collapse='*')
  if(!nzchar(fe)) { fe <- "1" }
  
  frm <- as.formula(
    paste('y ~', paste(c(fe, re_str), collapse=' + '))
  )
  
  if(length(unique(dd$Trial)) < 2) {
    # can't do any stats
    mod <- NULL
    .aov <- NULL
    em <- NULL
    pairwise <- NULL
  } else {
    FUN <- ifelse(is.null(re_str), stats::lm, lme4::lmer)
    mod <- do.call(FUN, list(formula=frm, data=dd))
    
    .aov <- car::Anova(mod, type=ifelse(fe[1] == "1", 'III', 'II'))
    
    ravedash::logger('built linear model, starting post hoc tests', calc_delta = TRUE)
    # est. marg means initial object, used by other
    # functions to get all the contrasts
    
    em <- emmeans::emmeans(
      mod, as.formula(sprintf(" ~ %s", fe)), infer=c(F,T)
    )
    
    ravedash::logger('Got emm', calc_delta = TRUE)
    
    pairwise <- emmeans::contrast(
      em, 'pairwise'
    )
    ravedash::logger('Got pairwise contrasts', calc_delta = TRUE)
    ravedash::logger('Got ANOVA', calc_delta = TRUE)
  }
  
  # here we have a chance to stratify rather than do
  # all-possible pairwise comparisons (save your alpha!)
  stratified_contrasts <- NULL
  if(length(fe) > 1) {
    stratified_contrasts <- get_stratified_contrasts(em)
  }
  
  ## get the interaction contrasts
  itx_contrasts <- NULL
  if(length(fe) == 2) {
    nm <- paste0(fe, collapse='_')
    
    itx_contrasts <- list(
      emmeans::contrast(em, interaction=c('pairwise', 'pairwise'))
    ) %>% setNames(nm)
    
  }
  
  if (length(fe) > 2) {
    fe_combn <- combn(fe, 2, simplify = FALSE)
    
    itx_contrasts <- sapply(fe_combn, function(groups) {
      emmeans::contrast(em,
                        interaction=c('pairwise', 'pairwise'), by=fe[!fe %in% groups]
      )
    }) %>% setNames(sapply(fe_combn, paste0, collapse='.'))
  }
  
  ravedash::logger('Got other contrasts', calc_delta = TRUE)
  
  # .aov <- car::Anova(mod, type=ifelse(
  #   fe[1] == "1", 'III', 'II')
  # )
  # 
  # ravedash::logger('Got ANOVA', calc_delta = TRUE)
  
  across_electrode_statistics <- list(
    condition_means = condition_means,
    model = mod,
    model_type = class(mod)[1],
    aov = .aov,
    emmeans = em,
    pairwise_contrasts = pairwise,
    fixed_effects = fe,
    random_effects = re,
    stratified_contrasts = stratified_contrasts,
    itx_contrasts = itx_contrasts,
    trials_not_included = sort(trial_outliers_list)
  )
}
```

```{rave build_by_trial_electrode_similarity_data, language="R", export="by_trial_electrode_similarity_data"}
# dd <- omnibus_results$data
by_trial_electrode_similarity_data <- NULL
# 
# if(!is.null(dd[['AnalysisLabel']])) {
#   
#   if(enable_second_condition_groupings) {
#     
#   } else {
#     # for each condition group, correlate the electrode responses across trials
#     by_trial_electrode_similarity_data <- 
#       lapply(split(dd, list(dd$AnalysisLabel, dd$Factor1)),
#              function(bb) {
#                bb <- bb[order(bb$Electrode, bb$Trial),]
#                
#                mat <- matrix(c(bb$y), nrow=length(unique(bb$Trial)),
#                              dimnames = list(NULL, unique(bb$Electrode)))
#                
#                cor(mat)
#              })
#   }
# }
```

```{rave build_data_for_export, language="R", export='data_for_export', cue = "always"}
# do nothing if we're just knitting this pipeline
if( getOption("knit_rave_pipelines", default = FALSE) ) {
  # list2env(list("electrodes_to_export" = repository$power$dimnames$Electrode[1]), envir = environment())
  data_for_export <- NULL
} else {
  
  # ravedash::logger("1024::Electrodes to export:[", electrodes_to_export, ']', level = 'warning')
  
  prog <- shidashi::shiny_progress("Building export data", max=4,
                                   shiny_auto_close = TRUE)
  
  data_for_export = FALSE
  
  electrodes_to_keep <- dipsaus::parse_svec(electrodes_to_export, sep=',|;', connect  = ':-')
  
  electrodes_to_keep %<>% remove_from_arr(repository$power$dimnames$Electrode, `%in%`, negate=TRUE)
  
  ## check for ROI exclusion criteria
  if(electrodes_to_export_roi_name!='none') {
    v = if(electrodes_to_export_roi_name== 'Custom ROI') {
      
    } else {
      electrodes_to_export_roi_name
    }
    lbls <- subset(repository$electrode_table, Electrode %in% electrodes_to_keep, select=v, drop=TRUE)
    electrodes_to_keep = electrodes_to_keep[lbls %in% electrodes_to_export_roi_categories]
  }
  
  if(!length(electrodes_to_keep)){ 
    stop("No electrodes were found passing all selection criteria")
  } 
  
  prog$inc("Baseline data [export loop]")
  
  ## ensure the data are available
  raveio::power_baseline(
    repository,
    baseline_windows = baseline_settings$window,
    method = get_unit_of_analysis(baseline_settings$unit_of_analysis),
    units = get_baseline_scope(baseline_settings$scope),
    signal_type = repository$signal_type,
    electrodes = electrodes_to_keep
  )
  
  # We're ensuring in the module that the electrodes have already 
  # been baselined etc by calling run() with our requested electrodes
  # we can grab the data directly from pluriform power
  # first we work on the tensor (one per analysis setting,
  # because of potential overlap), then flatten if requested at the end
  
  dd <- paste0('pe_export_', stringr::str_replace_all(format(Sys.time(), "%X__%b_%d_%Y"), stringr::fixed(':'), '_'))
  out_path <- file.path(repository$subject$path, 'power_explorer', dd)
  
  raveio::dir_create2(out_path)
  
  uoa <- get_unit_of_analysis_varname(baseline_settings$unit_of_analysis)
  for(current_electrode in electrodes_to_keep) {
    
    tensors <- lapply(analysis_settings_clean, function(asc) {
      # asc = analysis_settings_clean[[1]]
      ravedash::logger('Working on ', asc$label)
      
      current_tensor = subset(repository$power$baselined, 
                              Electrode ~ Electrode %in% current_electrode)
      
      # 
      # Work on the TRIAL dimension
      tet <- trial_export_types()
      # first assume keeping all the trials
      trials_to_keep = repository$power$dimnames$Trial
      
      # if subset requested
      if(trials_to_export %in% c(tet$RAW_GRP, tet$CLP_GRP, tet$CLP_CND) ) {
        trials_to_keep <- sort(
          unique(c(unlist(sapply(analysis_groups, `[[`, 'trials'))))
        )
      }
      
      # Here we shift the data using pluriform power function
      shifted_tensor <- get_pluriform_power(
        baselined_data=current_tensor,
        trial_indices = trials_to_keep,
        events = repository$epoch$table,
        epoch_event_types = get_available_events(repository$epoch$columns),
        trial_outliers_list=unlist(trial_outliers_list),
        event_of_interest = asc$event,
        sample_rate = repository$subject$power_sample_rate,
        final_data_only = TRUE
      )
      # rm(current_tensor)
      
      # by default dimnames are character
      dn = lapply(dimnames(shifted_tensor), as.numeric)
      
      # do we need to collapse?
      if(trials_to_export == tet$CLP_GRP) {
        with_trials <- which_have_trials(analysis_groups)
        
        # note the sapply here to concat the result
        by_group <- sapply(analysis_groups[with_trials], function(ag) {
          # here we have to rely on dn$Trial because subsetting may have occurred
          # vs. the original tensor
          ind <- (dn$Trial %in% ag$trials)
          ravetools::collapse(shifted_tensor[,,ind,,drop=FALSE], keep=c(1,2,4))
        })
        
        # this loses dimnames, so add them back
        shifted_tensor = tensor_reshape(mat = by_group, 
                                        orig_dim = dim(shifted_tensor), pivot=3)
        
        dn$Trial = unname(sapply(analysis_groups[with_trials], `[[`, 'label'))
        dimnames(shifted_tensor) = dn
      }
      
      # add a name for the trial groups, the default label is
      # taken from the Condition Column (in the epoch table)
      attr_TrialLabel = subset(repository$epoch$table, 
                               Trial %in% dn$Trial, 
                               select=c('Trial', condition_variable)
      ) %>% data.table::setorder('Trial')
      
      attr_TrialLabel$OrigCondition = attr_TrialLabel[[condition_variable]]
      
      # add trial groups if we have them  
      for(ag in which_have_trials(analysis_groups)) {
        ind = attr_TrialLabel$Trial %in% analysis_groups[[ag]]$trials
        attr_TrialLabel$Condition[ind] = names(analysis_groups)[ag]
      }
      
      # TIME DIMENSION
      tmet <- time_export_types()
      # see if any time points can be dropped
      if(times_to_export %in% c(tmet$CLP_AWO, tmet$RAW_AWO)) {
        ind <- dn$Time %within% asc$time
        
        shifted_tensor = shifted_tensor[,ind,,,drop=FALSE]
        dn$Time = as.numeric(dimnames(shifted_tensor)$Time)
      }
      
      if(times_to_export == tmet$CLP_AWO) {
        tmp = ravetools::collapse(shifted_tensor, keep=c(1,3:4))
        
        dim(tmp) = c(dim(tmp), 1)
        
        # perm to put time dimension back in it's place
        shifted_tensor <- aperm(tmp, c(1,4,2,3))
        
        # all(0==range(shifted_tensor[,1,,] - tmp[,,,1]))
        dn$Time = asc$label
        dimnames(shifted_tensor) = dn
      }
      
      #
      # Frequency dimension
      fet = frequency_export_types()
      if(frequencies_to_export %in% c(fet$CLP_AWO, fet$RAW_AWO)) {
        ff <- dn$Frequency %within% asc$frequency
        shifted_tensor = shifted_tensor[ff,,,,drop=FALSE]
      }
      dn$Frequency = as.numeric(dimnames(shifted_tensor)$Frequency)
      
      if(frequencies_to_export == fet$CLP_AWO) {
        tmp = ravetools::collapse(shifted_tensor, keep = 2:4)
        dim(tmp) = c(dim(tmp),1)
        
        # perm to put time dimension back in it's place
        shifted_tensor <- aperm(tmp, c(4,1:3))
        # all(0==range(current_tensor[1,,,] - tmp[,,,1]))
        dn$Frequency = asc$label
        dimnames(shifted_tensor) = dn
      }
      
      ## add in the trial label last
      # checks here to make sure nothing weird happened. 
      if(length(attr_TrialLabel$Condition) == length(dn$Trial) &&
         all(0 == (dn$Trial - attr_TrialLabel$Trial))) {
        attr(shifted_tensor, 'TrialLabel') = attr_TrialLabel$Condition
        attr(shifted_tensor, 'OrigTrialLabel') = attr_TrialLabel$OrigCondition
        
      } else {
        ravedash::logger(level='warning', "Could not apply trial labels. Length mismatch between labels (", nrow(attr_TrialLabel),
                         ") and  trials (", length(dn$Trial), "), or trial numbers didn't line up")
      }
      
      return(shifted_tensor)
    })
    
    flat_tables <- mapply(function(tensor, asc) {
      
      tbl <- data.table::as.data.table(
        reshape2::melt(tensor[drop = FALSE], value.name = uoa)
      )
      
      tbl$AnalysisGroup = asc$label
      
      # Add in necessary meta data
      
      # add in the trial label if one was calculated above
      if(!is.null(attributes(tensor)[['TrialLabel']])) {
        df <- data.table::data.table(
          Trial = as.numeric(dimnames(tensor)$Trial),
          TrialLabel = attributes(tensor)[['TrialLabel']],
          OrigTrialLabel = attributes(tensor)[['OrigTrialLabel']]
        )
        
        tbl %<>% merge(df, all.y=FALSE, all.x=TRUE)
      }
      
      return(tbl)
    }, tensors, analysis_settings_clean, SIMPLIFY = FALSE)
    
    if(!data.table::is.data.table(flat_tables)) {
      flat_tables <- rutabaga::rbind_list(flat_tables)
    }
    
    # convert factors back to characters
    flat_tables %<>% lapply(function(x) {
      if(is.factor(x)) {
        x <- as.character(x)
      }
      x
    }) %>% as.data.frame
    
    # if frequency or Time is just a label redundant with analysis group, then remove to save space
    if(identical(flat_tables$Frequency, flat_tables$AnalysisGroup)) {
      flat_tables$Frequency <- NULL
    }
    
    if(identical(flat_tables$Time, flat_tables$AnalysisGroup)) {
      flat_tables$Time <- NULL
    }
    
    data.table::fwrite(
      row.names = FALSE,
      flat_tables,
      file=file.path(out_path, sprintf('%s_%s_e%04d.csv', repository$subject$project_name, repository$subject$subject_code, current_electrode))
    )
  }
  
  # strip out redundant/uninformative details
  clean_settings <- function(ascs) {
    lapply(ascs, function(asc) {
      asc$frequency_dd <- NULL
      asc$subject_code <- NULL
      asc$project_name <- NULL
      
      if(!isTRUE(asc$censor_info$enabled)) {
        asc$censor_info <- NULL
      }
      
      asc
    })
  }
  
  # details on how electrodes were processed / anatomy 
  metadata=list(
    subject = repository$subject$subject_code,
    project = repository$subject$project_name,
    baseline_window = paste0(collapse=':', baseline_settings$window[[1]]), 
    baseline_scope = baseline_settings$scope[[1]],
    unit = uoa,
    signal_type = repository$signal_type,
    analyis_settings = clean_settings(analysis_settings_clean),
    reference = subset(repository$reference_table, Electrode %in% electrodes_to_keep),
    electrodes = subset(repository$electrode_table, Electrode %in% electrodes_to_keep)
  )
  
  raveio::save_yaml(
    metadata, file = file.path(out_path, 'metadata.yaml')
  )
  
  # target result for this block is the path to the exported data
  data_for_export <- out_path
}
```

```{rave build_data_for_group_analysis, language="R", export='data_for_group_analysis'}

data_for_group_analysis <- list()

data_for_group_analysis$baseline_settings <- baseline_settings
data_for_group_analysis$analysis_settings_clean <- analysis_settings_clean

data_for_group_analysis$electrode_information <- subset(repository$electrode_table, repository$electrode_table$Electrode %in% repository$electrode_list)

data_for_group_analysis$over_time_by_electrode_data <- over_time_by_electrode_data

data_for_group_analysis$omnibus_stats <- omnibus_results$stats
data_for_group_analysis$omnibus_data <- omnibus_results$data_with_outliers
```

```{r build, echo=FALSE, results='hide'}
build_pipeline(make_file = "make-power_explorer.R")
```

```{r visualize, echo=FALSE}
Sys.setenv("RAVE_PIPELINE" = normalizePath("."))
ravepipeline::pipeline_visualize()
```
